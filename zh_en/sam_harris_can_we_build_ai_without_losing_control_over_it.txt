时间： 0:12
zh-cn:我想谈论一种我们很多人都经历过的来自于直觉上的失误。它让人们无法察觉到一种特定危险的存在。我要向大家描述一个情景，一个我觉得既令人害怕，却又很可能发生的情景。这样一个组合的出现，显然不是一个好的征兆。不过，在座的大部分人都会觉得，我要谈论的这件事其实挺酷的。
en:I&#39;m going to talkabout a failure of intuitionthat many of us suffer from.It&#39;s really a failureto detect a certain kind of danger.I&#39;m going to describe a scenariothat I think is both terrifyingand likely to occur,and that&#39;s not a good combination,as it turns out.And yet rather than be scared,most of you will feelthat what I&#39;m talking aboutis kind of cool.
时间： 0:36
zh-cn:我将描述我们从人工智能中获得的好处，将怎样彻底地毁灭我们。事实上，想看到人工智能最终不摧毁我们是很难的，或者说它必将驱使我们自我毁灭。如果你和我有共同点，你会发现思考这些问题是相当有趣的。而这种反应就是问题的一部分。因为这种想法应该使你感到担忧。假如我想在这个演讲中让你们相信，我们因为气候变化或者其他灾难，很可能会遭受全球性的饥荒，同时，你们的子孙后辈都可能在这样的饥荒中挣扎求生，你们就不会觉得“真有趣，我喜欢这个TED演讲。”
en:I&#39;m going to describehow the gains we makein artificial intelligencecould ultimately destroy us.And in fact, I think it&#39;s very difficultto see how they won&#39;t destroy usor inspire us to destroy ourselves.And yet if you&#39;re anything like me,you&#39;ll find that it&#39;s funto think about these things.And that response is part of the problem.OK? That response should worry you.And if I were to convince you in this talkthat we were likelyto suffer a global famine,either because of climate changeor some other catastrophe,and that your grandchildren,or their grandchildren,are very likely to live like this,you wouldn&#39;t think,&quot;Interesting.I like this TED Talk.&quot;
时间： 1:20
zh-cn:因为饥荒一点都不有趣。不过，科幻小说中的死亡往往却引人入胜。所以我现在最担心的一个问题是，人们对人工智能的发展将带来的危险，似乎还没有形成一个正确的认识。我也同样如此，所以我想在这个演讲中和大家一起探讨。
en:Famine isn&#39;t fun.Death by science fiction,on the other hand, is fun,and one of the things that worries me mostabout the development of AI at this pointis that we seem unable to marshalan appropriate emotional responseto the dangers that lie ahead.I am unable to marshal this response,and I&#39;m giving this talk.
时间： 1:41
zh-cn:我们就像站在了两扇门前。在第一扇门后面，我们停下打造智能机器的脚步。某些原因也使我们停止了对电脑软件和硬件的升级。现在让我们想一下为什么会这样。我的意思是，当我们认识到智能和自动化不可估量的价值时，我们总会竭尽所能的改善这些科技。那么，什么会使我们停下脚步呢？一场大规模的核战争？一次全球性的瘟疫？一个小行星撞击了地球？或者是贾斯汀·比伯成为了美国总统？
en:It&#39;s as though we stand before two doors.Behind door number one,we stop making progressin building intelligent machines.Our computer hardware and softwarejust stops getting better for some reason.Now take a momentto consider why this might happen.I mean, given how valuableintelligence and automation are,we will continue to improve our technologyif we are at all able to.What could stop us from doing this?A full-scale nuclear war?A global pandemic?An asteroid impact?Justin Bieber becomingpresident of the United States?
时间： 2:19
zh-cn:（笑声）
en:(Laughter)
时间： 2:23
zh-cn:重点是，总有一个事物会摧毁人类现有的文明。你需要思考这个灾难究竟有多恐怖，才会永久性地阻止我们发展科技，永久性的。光想想它，就觉得这将是人类历史上能发生的最惨绝人寰的事了。
en:The point is, something would have todestroy civilization as we know it.You have to imaginehow bad it would have to beto prevent us from makingimprovements in our technologypermanently,generation after generation.Almost by definition,this is the worst thingthat&#39;s ever happened in human history.
时间： 2:43
zh-cn:那么，我们唯一剩下的选择，就藏在第二扇门的后面，那就是我们持续改进我们的智能机器，永不停歇。在将来的某一天，我们会造出比我们更聪明的机器，一旦我们有了比我们更聪明的机器，它们将进行自我改进。然后我们就会承担着数学家IJ Good 所说的“智能爆炸”的风险，（科技进步的）进程将不再受我们的控制。
en:So the only alternative,and this is what liesbehind door number two,is that we continueto improve our intelligent machinesyear after year after year.At a certain point, we will buildmachines that are smarter than we are,and once we have machinesthat are smarter than we are,they will begin to improve themselves.And then we risk whatthe mathematician IJ Good calledan &quot;intelligence explosion,&quot;that the process could get away from us.
时间： 3:09
zh-cn:现在我们时常会看到这样一些讽刺漫画，我们总会担心受到一些不怀好意的机器人军队的攻击。但这不是最可能出现的事情。我们的机器不会自动变得邪恶。所以，我们唯一的顾虑就是我们将会打造比我们人类更有竞争力的机器。而一旦我们和它们的目标不一致，我们将会被摧毁。
en:Now, this is often caricatured,as I have here,as a fear that armies of malicious robotswill attack us.But that isn&#39;t the most likely scenario.It&#39;s not that our machineswill become spontaneously malevolent.The concern is reallythat we will build machinesthat are so muchmore competent than we arethat the slightest divergencebetween their goals and our owncould destroy us.
时间： 3:34
zh-cn:想想我们与蚂蚁的关系吧。我们不讨厌它们，我们不会去主动去伤害它们。实际上，我们经常会尽量避免伤害蚂蚁。我们会选择从它们身边走过。但只要它们的存在妨碍到了我们达成目标，比如说当我们在建造这样一个建筑，我们会毫不手软地杀掉它们。所以我们的顾虑是，终将有一天我们打造的机器，不管它们是否有意识，它们终将会以我们对待蚂蚁的方式来对待我们。
en:Just think about how we relate to ants.We don&#39;t hate them.We don&#39;t go out of our way to harm them.In fact, sometimeswe take pains not to harm them.We step over them on the sidewalk.But whenever their presenceseriously conflicts with one of our goals,let&#39;s say when constructinga building like this one,we annihilate them without a qualm.The concern is that we willone day build machinesthat, whether they&#39;re conscious or not,could treat us with similar disregard.
时间： 4:04
zh-cn:我想很多人会说这很遥远。我打赌你们中有些人还会怀疑超级人工智能是否可能实现，认为我是在小题大做。但是你很快会发现以下这些假设中的某一个是有问题的。下面是仅有的三种假设：
en:Now, I suspect this seemsfar-fetched to many of you.I bet there are those of you who doubtthat superintelligent AI is possible,much less inevitable.But then you must find something wrongwith one of the following assumptions.And there are only three of them.
时间： 4:22
zh-cn:第一，智慧可以被看做物理系统中的信息处理过程。事实上，这不仅仅是一个假设。我们已经在有些机器中嵌入了智能系统，这些机器中很多已经有着超越普通人的智慧了。而且，我们也知道任何一点小事都可以引发所谓的“普遍智慧”，这是一种可以在不同领域间灵活思考的能力，因为我们的大脑已经成功做到了这些。对吧？我的意思是，大脑里其实都是原子，只要我们继续建造这些原子体系，我们就能实现越来越多的智慧行为，我们最终将会，当然除非我们被干扰，我们最终将会给我们的机器赋予广泛意义上的智能。
en:Intelligence is a matter of informationprocessing in physical systems.Actually, this is a little bit morethan an assumption.We have already builtnarrow intelligence into our machines,and many of these machines performat a level of superhumanintelligence already.And we know that mere mattercan give rise to what is called&quot;general intelligence,&quot;an ability to think flexiblyacross multiple domains,because our brains have managed it. Right?I mean, there&#39;s just atoms in here,and as long as we continueto build systems of atomsthat display more and moreintelligent behavior,we will eventually,unless we are interrupted,we will eventuallybuild general intelligenceinto our machines.
时间： 5:10
zh-cn:我们要知道这个进程的速度并不重要，因为任何进程都足够让我们走进死胡同。甚至不需要考虑摩尔定律，也不需要用指数函数来衡量，这一切顺其自然都会发生。
en:It&#39;s crucial to realizethat the rate of progress doesn&#39;t matter,because any progressis enough to get us into the end zone.We don&#39;t need Moore&#39;s law to continue.We don&#39;t need exponential progress.We just need to keep going.
时间： 5:24
zh-cn:第二个假设是，我们会一直创新。去继续改进我们的智能机器。由于智慧的价值就是——提供我们所珍爱的事物，或是用于保护我们所珍视的一切。智慧就是我们最有价值的资源。所以我们想继续革新它。因为我们有很多需要迫切解决的问题。我们想要治愈像阿兹海默症和癌症这样的疾病，我们想要了解经济系统，想要改善我们的气候科学，所以只要可能，我们就会将革新继续下去。而且革新的列车早已驶出， 车上却没有刹车。
en:The second assumptionis that we will keep going.We will continue to improveour intelligent machines.And given the value of intelligence —I mean, intelligence is eitherthe source of everything we valueor we need it to safeguardeverything we value.It is our most valuable resource.So we want to do this.We have problemsthat we desperately need to solve.We want to cure diseaseslike Alzheimer&#39;s and cancer.We want to understand economic systems.We want to improve our climate science.So we will do this, if we can.The train is already out of the station,and there&#39;s no brake to pull.
时间： 6:04
zh-cn:第三种假设是：人类没有登上智慧的巅峰，甚至连接近可能都谈不上。这个想法十分关键。这就是为什么我们所处的环境是很危险的，这也是为什么我们对风险的直觉是不可靠的。
en:Finally, we don&#39;t standon a peak of intelligence,or anywhere near it, likely.And this really is the crucial insight.This is what makesour situation so precarious,and this is what makes our intuitionsabout risk so unreliable.
时间： 6:22
zh-cn:现在，请大家想一下谁是世界上最聪明的人。几乎每个人的候选名单里都会有约翰·冯·诺伊曼。冯·诺伊曼留给周围人的印象就是他是那个时代当中最杰出的数学家和物理学家，这些都是完好的记录在案的。即使他的故事里有一半是假的，都没有人会质疑他仍然是世界上最聪明的人之一。那么，让我们来看看智慧谱线吧。现在我们有了约翰·冯·诺伊曼，还有我们大家。另外还有一只鸡。
en:Now, just consider the smartest personwho has ever lived.On almost everyone&#39;s shortlist hereis John von Neumann.I mean, the impression that von Neumannmade on the people around him,and this included the greatestmathematicians and physicists of his time,is fairly well-documented.If only half the storiesabout him are half true,there&#39;s no questionhe&#39;s one of the smartest peoplewho has ever lived.So consider the spectrum of intelligence.Here we have John von Neumann.And then we have you and me.And then we have a chicken.
时间： 6:56
zh-cn:（笑声）
en:(Laughter)
时间： 6:58
zh-cn:抱歉，母鸡的位置应该在这。
en:Sorry, a chicken.
时间： 6:59
zh-cn:（笑声）
en:(Laughter)
时间： 7:00
zh-cn:这个演讲已经够严肃了，开个玩笑轻松一下。
en:There&#39;s no reason for me to make this talkmore depressing than it needs to be.
时间： 7:04
zh-cn:（笑声）
en:(Laughter)
时间： 7:07
zh-cn:然而，很可能的情况是，智慧谱线上的内容已远远超出了我们的认知，如果我们建造了比自身更聪明的机器，它们将非常可能以超乎寻常的方式延展这个谱线，最终超越人类。
en:It seems overwhelmingly likely, however,that the spectrum of intelligenceextends much furtherthan we currently conceive,and if we build machinesthat are more intelligent than we are,they will very likelyexplore this spectrumin ways that we can&#39;t imagine,and exceed us in waysthat we can&#39;t imagine.
时间： 7:26
zh-cn:仅仅从速度方面考虑，我们就能够意识到这一点。那么，现在让我们来想象一下我们刚建好一个超级人工智能机器，大概和斯坦福或是麻省理工学院的研究员的平均水平差不多吧。但是，电路板要比生物系统运行速度快一百万倍，所以这个机器思考起来会比那些打造它的大脑快一百万倍。当你让它运行一周后，它将能呈现出相当于人类智慧在20000年间发展出的水平，而这个过程将周而复始。那么，我们又怎么能理解，更不用说去制约一个以如此速度运行的机器呢？
en:And it&#39;s important to recognize thatthis is true by virtue of speed alone.Right? So imagine if we just builta superintelligent AIthat was no smarterthan your average team of researchersat Stanford or MIT.Well, electronic circuitsfunction about a million times fasterthan biochemical ones,so this machine should thinkabout a million times fasterthan the minds that built it.So you set it running for a week,and it will perform 20,000 yearsof human-level intellectual work,week after week after week.How could we even understand,much less constrain,a mind making this sort of progress?
时间： 8:07
zh-cn:坦白讲，另一件令人担心的事就是，我们考虑一下最理想的情景。想象我们正好做出了一个没有任何安全隐患的超级人工智能。我们有了一个前所未有的完美设计。就好像我们被赐予了一件神物，它能够准确的执行目标动作。这个机器将完美的节省人力工作。它设计出的机器能够再生产其他机器，去完成所有的人力工作。由太阳能供电，而成本的多少仅取决于原材料。那么，我们正在谈论的就是人力劳动的终结。也关乎脑力劳动的终结。
en:The other thing that&#39;s worrying, frankly,is that, imagine the best case scenario.So imagine we hit upon a designof superintelligent AIthat has no safety concerns.We have the perfect designthe first time around.It&#39;s as though we&#39;ve been handed an oraclethat behaves exactly as intended.Well, this machine would bethe perfect labor-saving device.It can design the machinethat can build the machinethat can do any physical work,powered by sunlight,more or less for the costof raw materials.So we&#39;re talking aboutthe end of human drudgery.We&#39;re also talking about the endof most intellectual work.
时间： 8:48
zh-cn:那在这种情况下，像我们这样的&quot;大猩猩&quot;还能有什么用呢？我们可以悠闲地玩飞盘，给彼此做按摩。服用一些迷药，穿一些奇装异服，整个世界都沉浸在狂欢节之中。
en:So what would apes like ourselvesdo in this circumstance?Well, we&#39;d be free to play Frisbeeand give each other massages.Add some LSD and somequestionable wardrobe choices,and the whole worldcould be like Burning Man.
时间： 9:01
zh-cn:（笑声）
en:(Laughter)
时间： 9:05
zh-cn:那可能听起来挺棒的，不过让我们扪心自问，在现有的经济和政治体制下，这意味着什么？我们很可能会目睹前所未有的贫富差距和失业率。有钱人不愿意马上把这笔新的财富贡献出来服务社会，这时一些千万富翁能够优雅地登上商业杂志的封面，而剩下的人可能都在挨饿。
en:Now, that might sound pretty good,but ask yourself what would happenunder our current economicand political order?It seems likely that we would witnessa level of wealth inequalityand unemploymentthat we have never seen before.Absent a willingnessto immediately put this new wealthto the service of all humanity,a few trillionaires could gracethe covers of our business magazineswhile the rest of the worldwould be free to starve.
时间： 9:33
zh-cn:如果听说硅谷里的公司即将造出超级人工智能，俄国人和中国人会采取怎样的行动呢？那个机器将能够以一种前所未有的能力去开展由领土问题和网络问题引发的战争。这是一个胜者为王的世界。机器世界中的半年，在现实世界至少会相当于50万年。所以仅仅是关于这种科技突破的传闻，就可以让我们的种族丧失理智。
en:And what would the Russiansor the Chinese doif they heard that some companyin Silicon Valleywas about to deploy a superintelligent AI?This machine would be capableof waging war,whether terrestrial or cyber,with unprecedented power.This is a winner-take-all scenario.To be six months aheadof the competition hereis to be 500,000 years ahead,at a minimum.So it seems that even mere rumorsof this kind of breakthroughcould cause our species to go berserk.
时间：10:05
zh-cn:在我的观念里，当前最可怕的东西正是人工智能的研究人员安慰我们的那些话。最常见的理由就是关于时间。他们会说，现在开始担心还为时尚早。这很可能是50年或者100年之后才需要担心的事。一个研究人员曾说过，“担心人工智能的安全性就好比担心火星上人口过多一样。”这就是硅谷版本的“不要杞人忧天。”
en:Now, one of the most frightening things,in my view, at this moment,are the kinds of thingsthat AI researchers saywhen they want to be reassuring.And the most common reasonwe&#39;re told not to worry is time.This is all a long way off,don&#39;t you know.This is probably 50 or 100 years away.One researcher has said,&quot;Worrying about AI safetyis like worryingabout overpopulation on Mars.&quot;This is the Silicon Valley versionof &quot;don&#39;t worry yourpretty little head about it.&quot;
时间：10:37
zh-cn:（笑声）
en:(Laughter)
时间：10:38
zh-cn:似乎没有人注意到以时间作为参考系是得不出合理的结论的。如果说智慧只包括信息处理，然后我们继续改善这些机器，那么我们终将生产出超级智能。但是，我们无法预估将花费多长时间来创造实现这一切的安全环境。我再重复一遍。我们无法预估将花费多长时间来创造实现这一切的安全环境。
en:No one seems to noticethat referencing the time horizonis a total non sequitur.If intelligence is just a matterof information processing,and we continue to improve our machines,we will producesome form of superintelligence.And we have no ideahow long it will take usto create the conditionsto do that safely.Let me say that again.We have no idea how long it will take usto create the conditionsto do that safely.
时间：11:11
zh-cn:你们可能没有注意过，50年的概念已今非昔比。这是用月来衡量50年的样子。（每个点表示一个月）红色的点是代表苹果手机出现的时间。这是《辛普森一家》（动画片）在电视上播出以来的时间。要做好准备面对人类历史上前所未有的挑战，50年时间并不是很长。就像我刚才说的，我们对确定会来临的事情做出了不合理的回应。
en:And if you haven&#39;t noticed,50 years is not what it used to be.This is 50 years in months.This is how long we&#39;ve had the iPhone.This is how long &quot;The Simpsons&quot;has been on television.Fifty years is not that much timeto meet one of the greatest challengesour species will ever face.Once again, we seem to be failingto have an appropriate emotional responseto what we have every reasonto believe is coming.
时间：11:37
zh-cn:计算机科学家斯图尔特·罗素给出了一个极好的类比。他说，想象我们从外太空接收到一条讯息，上面写着：“地球上的人类，我们将在五十年后到达你们的星球，做好准备吧。”于是我们就开始倒计时，直到它们的“母舰”着陆吗？在这种情况下我们会感到更紧迫。
en:The computer scientist Stuart Russellhas a nice analogy here.He said, imagine that we receiveda message from an alien civilization,which read:&quot;People of Earth,we will arrive on your planet in 50 years.Get ready.&quot;And now we&#39;re just counting downthe months until the mothership lands?We would feel a littlemore urgency than we do.
时间：12:03
zh-cn:另外一个试图安慰我们的理由是，那些机器必须拥有和我们一样的价值观，因为它们将会是我们自身的延伸。它们将会被嫁接到我们的大脑上，我们将会成它们的边缘系统。现在我们再思考一下最安全的，也是唯一经慎重考虑后推荐的发展方向，是将这项技术直接植入我们大脑。这也许确实是最安全的，也是唯一慎重的发展方向，但通常在我们把它塞进脑袋之前，会充分考虑这项技术的安全性。
en:Another reason we&#39;re told not to worryis that these machinescan&#39;t help but share our valuesbecause they will be literallyextensions of ourselves.They&#39;ll be grafted onto our brains,and we&#39;ll essentiallybecome their limbic systems.Now take a moment to considerthat the safestand only prudent path forward,recommended,is to implant this technologydirectly into our brains.Now, this may in fact be the safestand only prudent path forward,but usually one&#39;s safety concernsabout a technologyhave to be pretty much worked outbefore you stick it inside your head.
时间：12:35
zh-cn:（笑声）
en:(Laughter)
时间：12:37
zh-cn:更深一层的问题是：仅仅制造出超级人工智能机器可能要比既制造超级人工智能，又让其拥有能让我们的思想和超级人工智能无缝对接的完整的神经科学系统要简单很多。而做这些研究的公司或政府，很可能将彼此视作竞争对手，因为赢得了比赛就意味着称霸了世界，前提是不在刚成功后就将其销毁，所以结论是：简单的选项一定会被先实现。
en:The deeper problem is thatbuilding superintelligent AI on its ownseems likely to be easierthan building superintelligent AIand having the completed neurosciencethat allows us to seamlesslyintegrate our minds with it.And given that the companiesand governments doing this workare likely to perceive themselvesas being in a race against all others,given that to win this raceis to win the world,provided you don&#39;t destroy itin the next moment,then it seems likelythat whatever is easier to dowill get done first.
时间：13:09
zh-cn:但很遗憾，除了建议更多人去思考这个问题，我对此并无解决方案。我觉得在人工智能问题上，我们需要一个“曼哈顿计划”（二战核武器研究计划），不是用于讨论如何制造人工智能，因为我们一定会这么做，而是去避免军备竞赛，最终以一种有利于我们的方式去打造它。当你在谈论一个可以自我改造的超级人工智能时，我们似乎只有一次正确搭建初始系统的机会，而这个正确的初始系统需要我们在经济以及政治上做出很大的努力。
en:Now, unfortunately,I don&#39;t have a solution to this problem,apart from recommendingthat more of us think about it.I think we need somethinglike a Manhattan Projecton the topic of artificial intelligence.Not to build it, because I thinkwe&#39;ll inevitably do that,but to understandhow to avoid an arms raceand to build it in a waythat is aligned with our interests.When you&#39;re talkingabout superintelligent AIthat can make changes to itself,it seems that we only have one chanceto get the initial conditions right,and even then we will need to absorbthe economic and politicalconsequences of getting them right.
时间：13:44
zh-cn:但是当我们承认信息处理是智慧的源头，承认一些电脑系统是智能的基础，承认我们会不断改善这些系统，承认我们现存的认知远没有达到极限，将很可能被超越，我们又必须同时承认我们在某种意义上正在创造一个新的“上帝”。现在正是思考人类是否能与这个“上帝”和睦相处的最佳时机。
en:But the moment we admitthat information processingis the source of intelligence,that some appropriate computational systemis what the basis of intelligence is,and we admit that we will improvethese systems continuously,and we admit that the horizonof cognition very likely far exceedswhat we currently know,then we have to admitthat we are in the processof building some sort of god.Now would be a good timeto make sure it&#39;s a god we can live with.
时间：14:19
zh-cn:非常感谢！
en:Thank you very much.
时间：14:20
zh-cn:（掌声）
en:(Applause)
